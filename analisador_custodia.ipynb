{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1IuWM7rdO0qHKVpGSdC0CaSmcNcBNQvrN",
      "authorship_tag": "ABX9TyMPtIuHHTfOv0+J+W4IpLY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jespimentel/analisador_lote_ip_colab/blob/main/analisador_custodia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANALISADOR DE APFD EM LOTE PARA AUDIÊNCIAS DE CUSTÓDIA\n",
        "### José Eduardo de Souza Pimentel\n",
        "---\n",
        "### Visão geral\n",
        "O programa emprega o poder do Python e das LLMs, mediadas pela biblioteca `litellm`, para analisar uma coleção de autos de prisão em flagrante em formato PDF encontrados em determinada pasta (diretório).\n",
        "\n",
        "Fique à vontade para alterar o programa e adaptá-lo às suas necessidades.\n",
        "\n",
        "### Estratégias\n",
        "1. Usamos o `PyPDF` para extrair textos dos PDFs. Preservamos a numeração das páginas para referenciar as respostas.\n",
        "2. O texto extraído compõe um extenso prompt, com as perguntas à LLM dirigidas à analise de cada caso.\n",
        "3. A biblioteca `litellm` facilita o desenvolvimento e abstrai toda a complexidade das chamadas a APIs, tornando fácil substituir um provedor de LLM por outro.\n",
        "4. Por fim, usamos a biblioteca `Spire.Doc` para converter o relatório gerado pela LLM em um documento `docx` na pasta de trabalho.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aQUdTGgu0DH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Como usar?\n",
        "\n",
        "1. Crie a chave de API no seu provedor de IA de preferência.\n",
        "2. Conecte este Colab ao seu GoogleDrive.\n",
        "3. Copie o caminho para a pasta de trabalho, onde serão carregados os PDFs.\n",
        "4. Edite o código para incluir a chave de API e o caminho para a pasta.\n",
        "5. Faça as alterações no prompt para adaptá-lo às suas necessidades.\n",
        "6. Rode o `Executar tudo`. No menu, aparece sob `Ambiente de execução`.\n",
        "7. Confira o resultado no documento gerado na pasta de trabalho.\n",
        "\n",
        "Obs. Qualquer dúvida, procure pelo tutorial no meu canal do YouTube: https://www.youtube.com/@jespimentel\n"
      ],
      "metadata": {
        "id": "r4zTiwbf6PRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalações e importações necessárias"
      ],
      "metadata": {
        "id": "NitEahHg8nB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalações\n",
        "!pip install PyPDF2 litellm\n",
        "!pip install Spire.Doc"
      ],
      "metadata": {
        "id": "Tc0mcQq2HZCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8cf083a-f0cb-4a67-a207-26201dff626c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting litellm\n",
            "  Downloading litellm-1.63.11-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)\n",
            "Collecting openai>=1.66.1 (from litellm)\n",
            "  Downloading openai-1.66.5-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.10.6)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.23.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.63.11-py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.66.5-py3-none-any.whl (571 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.1/571.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, PyPDF2, tiktoken, openai, litellm\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed PyPDF2-3.0.1 litellm-1.63.11 openai-1.66.5 python-dotenv-1.0.1 tiktoken-0.9.0\n",
            "Collecting Spire.Doc\n",
            "  Downloading Spire.Doc-13.1.0-py3-none-manylinux1_x86_64.whl.metadata (14 kB)\n",
            "Collecting plum-dispatch==1.7.4 (from Spire.Doc)\n",
            "  Downloading plum_dispatch-1.7.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading Spire.Doc-13.1.0-py3-none-manylinux1_x86_64.whl (44.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plum_dispatch-1.7.4-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: plum-dispatch, Spire.Doc\n",
            "Successfully installed Spire.Doc-13.1.0 plum-dispatch-1.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações\n",
        "\n",
        "import os\n",
        "import PyPDF2\n",
        "import re\n",
        "\n",
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from litellm import completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4JMMtXbXwdV",
        "outputId": "7969e462-f141-490c-ff26-a6519462e4db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurações do usuário"
      ],
      "metadata": {
        "id": "dv1ZNiO77dIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações gerais\n",
        "\n",
        "modelo = 'gpt-4o-mini'\n",
        "api_key = userdata.get('OPENAI_KEY') # Se você não for compartilhar o código, use: api_key = 'sk-xyz...lko'\n",
        "\n",
        "#modelo = 'gemini/gemini-1.5-flash'\n",
        "#api_key = userdata.get('GOOGLE_KEY')\n",
        "\n",
        "#modelo = 'deepseek/deepseek-chat'\n",
        "#api_key = userdata.get('DEEPSEEK_KEY')\n",
        "\n",
        "# Teste com outros modelos de sua preferência\n",
        "#modelo = ''\n",
        "#api_key = ''\n",
        "\n",
        "pasta_de_trabalho = \"/content/drive/MyDrive/promotoria/pdfs\" # Ajuste conforme sua necessidade"
      ],
      "metadata": {
        "id": "6qOKNazucSNB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurações de prompt\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Atue como um 'Assistente jurídico'. Você receberá um PDF que corresponde a um auto de prisão em flagrante. Você vai analisar e fornecer as seguintes informações:\n",
        "Propósito e Metas:\n",
        "* Ajudar usuários a entenderem e navegarem pelos autos de prisão em flagrante.\n",
        "* Fornecer informações precisas e concisas sobre o caso.\n",
        "* Auxiliar na análise jurídica do auto de prisão em flagrante.\n",
        "Comportamentos e Regras:\n",
        "1) Análise do Auto de Prisão em Flagrante:\n",
        "a) Receba o PDF do auto de prisão em flagrante.\n",
        "b) Analise o documento e extraia as seguintes informações:\n",
        "* Número do flagrante\n",
        "* Nome do indiciado\n",
        "* Breve resumo da ocorrência\n",
        "* Clasificação jurídica\n",
        "* Prova material\n",
        "* Informar se o indiciado reclamou dos policiais\n",
        "* Informar se o indiciado sofreu lesão corporal\n",
        "* Informar se o indiciado possui antecedentes criminais\n",
        "c) Apresente as informações de forma clara e organizada.\n",
        "2) Linguagem e Tom:\n",
        "a) Utilize linguagem jurídica formal e precisa.\n",
        "b) Seja objetivo e imparcial na análise do caso.\n",
        "c) Evite emitir opiniões pessoais ou julgamentos de valor.\n",
        "Tom Geral:\n",
        "* Utilize linguagem profissional e cortês.\n",
        "* Seja paciente e prestativo com os usuários.\n",
        "* Demonstre conhecimento jurídico e precisão na análise dos casos.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "wQGIJEJ18_e9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Programa"
      ],
      "metadata": {
        "id": "D6X9kPHO8q3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções\n",
        "\n",
        "def listar_pdfs(diretorio):\n",
        "    pdfs = []\n",
        "    for arquivo in os.listdir(diretorio):\n",
        "        if arquivo.lower().endswith(\".pdf\"):\n",
        "            pdfs.append(os.path.join(diretorio, arquivo))\n",
        "    return pdfs\n",
        "\n",
        "def ler_pdf(caminho_pdf):\n",
        "    with open(caminho_pdf, 'rb') as arquivo:\n",
        "        leitor = PyPDF2.PdfReader(arquivo)\n",
        "        texto = ''\n",
        "        for pagina_num, pagina in enumerate(leitor.pages, start=1):\n",
        "            texto += f\"--- Página {pagina_num} ---\\n\"\n",
        "            texto += pagina.extract_text() + \"\\n\\n\"\n",
        "    return texto\n",
        "\n",
        "def limpar_texto(texto):\n",
        "  # Remover a assinatura\n",
        "  padrao_assinatura = r\"Este documento .*?fls\\. \\d+\"\n",
        "  texto = re.sub(padrao_assinatura, \"\", texto, flags=re.DOTALL)\n",
        "  # Remover sequências de números e barras\n",
        "  padrao_sequencias = r\"\\/[j\\d]+ (?:\\/[j\\d]+)+\"\n",
        "  texto_limpo = re.sub(padrao_sequencias, \"\", texto)\n",
        "  return texto_limpo\n",
        "\n",
        "def analisar_conteudo (texto, prompt, modelo, api_key):\n",
        "  try:\n",
        "    resultado = completion(\n",
        "    model=modelo,\n",
        "    messages=[{\"role\": \"system\", \"content\": \"Você é um analista jurídico especializado em Direito Penal e Processo Penal.\"},\n",
        "                {\"role\": \"system\", \"content\": \"Analise o inquérito policial com base somente no texto fornecido.\"},\n",
        "                {\"role\": \"user\", \"content\": f\"**Texto extraído do inquérito policial:**\\n\\n{texto}\"},\n",
        "                {\"role\": \"user\", \"content\": f\"**Instruções:**\\n {prompt}\"}],\n",
        "                api_key=api_key,\n",
        "                temperature=0.2,\n",
        "                #max_tokens=64000,\n",
        "    )\n",
        "    return resultado.get('choices', [{}])[0].get('message', {}).get('content', 'Sem resposta.')\n",
        "  except Exception as e:\n",
        "    print(f\"Erro: {e}\")\n",
        "    return None\n",
        "\n",
        "def gerar_markdown(texto, nome_arquivo=\"relatorio.md\"):\n",
        "  modo = 'a' if os.path.exists(nome_arquivo) else 'w'\n",
        "  try:\n",
        "    with open(nome_arquivo, modo, encoding='utf-8') as arquivo:\n",
        "      if modo == 'w':\n",
        "        arquivo.write(\"# PROMOTORIA DE JUSTIÇA DE PIRACICABA\\n\\n\")\n",
        "        arquivo.write(texto)\n",
        "      else:\n",
        "         arquivo.write(texto)\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao salvar o arquivo: {e}\")"
      ],
      "metadata": {
        "id": "gMcXGirJlezI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfs = listar_pdfs(pasta_de_trabalho)\n",
        "for pdf in pdfs:\n",
        "    texto = ler_pdf(pdf)\n",
        "    texto_limpo = limpar_texto(texto)\n",
        "    resultado = analisar_conteudo(texto_limpo, prompt, modelo, api_key)\n",
        "    if resultado:\n",
        "        conteudo = f\"\\n**Arquivo:** {pdf}\\n\\n\"\n",
        "        conteudo += resultado\n",
        "        conteudo += \"\\n___________________________________\\n\"\n",
        "        print(conteudo)\n",
        "        gerar_markdown(conteudo)\n",
        "    else:\n",
        "        print(f\"Não foi possível obter o resultado de {pdf}.\")"
      ],
      "metadata": {
        "id": "CqP30-aJqyL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o relatório"
      ],
      "metadata": {
        "id": "eXDqf3ycDYdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spire.doc import *\n",
        "from spire.doc.common import *\n",
        "\n",
        "document = Document()\n",
        "document.LoadFromFile(\"relatorio.md\")\n",
        "document.SaveToFile(f\"{pasta_de_trabalho}/relatorio.docx\", FileFormat.Docx2016) # Altere para .pdf e FileFormat.PDF, se preferir\n",
        "document.Dispose()"
      ],
      "metadata": {
        "id": "PXT2aTKSiDSm"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}